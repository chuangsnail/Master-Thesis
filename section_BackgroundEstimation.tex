% !TEX root = main.tex

% TODO:
% REMARK:

\section{Background Estimation}
\label{sec:BkgEst}

	According to the simulation, the events of interests occupy diminant ratio under signal region selection(includes $\chi^2_{min}$, MVA-A, MVA-B strategy), but also about 4$\sim$6 \% of events which came from non-$t\bar{t}$ background are collected. Even though the selected events are under high signal purity, the randomly combined background events would contaminate the final measurement of asymmetry. In fact, the minority of background may still dilute the calculating results of $A'_{cp}$ critically in this precision measurement analysis. Thus, the background study should be attached importance to. The $A'_{cp}$ value of $t\bar{t}$ would be extracted, at the same time, backgrounds' contribution would be cast aside.

	It is a common and usual way to estimate background in data by using simulation samples. It depends more on the theoretical modeling and detector simulation with simulation sample. The background in simulation cannot be quite close to real data perfectly. This situation would disorder the asymmetry measurement eventually. It is suggested that in many high energy experiments' analysis to directly acquire background from real data. Therefore, the data-driven way is applied.
	
	In this analysis, it is found that the $M_{lb}$ variable really shows difference between signal and background in shape(Fig.\ref{BkgEst:fig:SR_sigbkg_Mlbshape}). Thus, with diverse shapes, it is an advantage to discern signal and background and then seperate them with template fit.

		\begin{figure}[H]
		\centering
			\subfigure[$\chi^2_{min}$, mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/chi2_SR_sig_bkg_shape_mu.pdf}}
			\subfigure[$\chi^2_{min}$, el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/chi2_SR_sig_bkg_shape_el.pdf}}\\
		\end{figure}
		\FloatBarrier
		\begin{figure}[H]
		\centering
			\subfigure[MVA(20 variables, MLP), mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/a05_MLP_SR_sig_bkg_shape_mu.pdf}}
			\subfigure[MVA(20 variables, MLP), el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/a05_MLP_SR_sig_bkg_shape_el.pdf}}\\
		\caption{Comparison of $M_{lb}$ shape between SR's signal and background}
		\label{BkgEst:fig:SR_sigbkg_Mlbshape}
		\end{figure}
		\FloatBarrier

	As mentioned that the W+jets-dominant CR's data is used to data-driven background in SR, it must be checked that how the similarity of $M_{lb}$'s pdf shape they have:

		\begin{figure}[H]
		\centering
			\subfigure[$\chi^2_{min}$, mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/chi2_MlbPDF_Cmp_mu.pdf}}
			\subfigure[$\chi^2_{min}$, el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/chi2_MlbPDF_Cmp_el.pdf}}\\
		\end{figure}
		\FloatBarrier
		\begin{figure}[H]
		\centering
			\subfigure[MVA(20 variables, MLP), mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/a05_MLP_MlbPDF_Cmp_mu.pdf}}
			\subfigure[MVA(20 variables, MLP), el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/a05_MLP_MlbPDF_Cmp_el.pdf}}\\
		\caption{Comparison of $M_{lb}$ shape between SR's background and CR's data}
		\label{BkgEst:fig:CRSR_Mlbshape}
		\end{figure}
		\FloatBarrier


	\subsection{Template Fit}
	\label{ssec:TemplateFit}

		The method $\textbf{Template Fit}$ is used to estimate background yields and subtract them in this analysis. The template in this method means a pdf(probability density function) with unvaried shape under specific variable's spectrum. Also following pdf's characteristic, the template have to be normalized(integrated area of this shape is unity). This template fit is one of general fitting with $\textbf{Maximum-Likelihood Method}$. 

		With respect to Maximum-Likelihood Method, it uses the likelihood function $\emph{L}$ and minimizes the $-2\ln{L}$ by computing resource to get the more appropriate parameters in function we want to predict. The signal and background yields in this analysis are both the target parameters in fitting. The likelihood function comes from joint pdf of N independent observation with $\emph{\textbf{X}}$ which is the set of observables, the joint pdf is Eq.\ref{eq:joint_eq}. 

		\begin{equation}
		P(X|\theta) = 􏱛 \prod_{i=1}^{N} f(X^i|\theta)
		\label{eq:joint_eq}
		\end{equation}

		 Eq.\ref{eq:joint_eq} shows the product of all i-th observation's function and the $\theta$ is the set of parameters in the pdf. When we substitute the observed data $\emph{\textbf{X}}^{\emph{\textbf{0}}}$ for variables $\emph{\textbf{X}}$, the PDF becomes the $\textbf{Likelihood function L(} \boldsymbol{\theta} \textbf{)}$:

		\begin{equation}
		L(\theta) = P(X^0|\theta) = 􏱛p(N|\theta) \prod_{i=1}^{N} f(X^i|\theta)
		\label{eq:likelihood_fn}
		\end{equation}

		There are $N$ times measurements in likelihood function. Also, the $p(N|\theta)$ is usually a poisson distribution in most common case because of the common counting condition. In order to get the most appropriate parameters to match the observed data, the larger value of likelihood function $L(\theta)$, the more matched the parameters demonstrate. Therefore, the maximum $L(\theta)$ case should be the target for final decision of parameters. However, the modern technics are usually used to minimize some values, so it is turned to negative sign and being have to be minimized. On the other hand, it is convenient to calculate with addition instead of product, so doing the natural logarithm on likelihood function make it easier(Eq.\ref{eq:nature_log_L}). In conclusion, Maximum-Likelihood method minimizes the $-2\ln{L(\theta)}$ and get the fitting parameters.

		\begin{equation}
		L(\theta) \implies \ln{L(\theta)} \; \; \; \; , \; \prod_{i=1}^{N} f(X^i|\theta) \implies \sum_{i=1}^{N} \ln{L(\theta)}
		\label{eq:nature_log_L}
		\end{equation}

		In the cases that the number of observation is also the parameters and as random variables, the $\textbf{extended-likelihood function}$ is often adopted. The extended-likelihood function includes the poisson distribution $p(N|\theta)$ of Eq.\ref{eq:likelihood_fn} in. So the extended-likelihood function shows as the pattern in Eq.\ref{eq:ext_likelihood_fn}. 

		\begin{equation}
		L(\theta)_{ext} = 􏱛p(N|\theta) \prod_{i=1}^{N} f(X^i|\theta) = \frac{e^{-\mu(\theta)}\mu(\theta)^{N}}{N!} \prod_{i=1}^{N} f(X^i|\theta)
		\label{eq:ext_likelihood_fn}
		\end{equation}


		In this analysis, there are signal and background templates being pdf shapes, and the only parameters of $\theta$ set are the event numbers of signal and background($n_{S}$, $n_{B}$). Thus the extended-likelihood function of this analysis is demonstrated as Eq.\ref{eq:ext_likelihood_fn_this}. The $f_{S}$, $f_{B}$ are the fraction of signal and background. That is to say, $f_{S}$ = $n_{S}/(n_{S}+n_{B})$, $f_{B}$ = $n_{B}/(n_{S}+n_{B})$, and the $P_{S}$ and $P_{B}$ are the templates of signal and background. Also, we just fit under the $M_{lb}$ variable(oboservable), so the $X^i$ in Eq.\ref{eq:ext_likelihood_fn} is $M_{lb}$.

		
		\begin{equation}
		\begin{split}
		L(n_{S},n_{B})_{ext} = \frac{e^{-(n_{S}+n_{B})}(n_{S}+n_{B})^{N}}{N!} \prod_{i=1}^{N} f(M_{lb}^i|n_{S},n_{B}) \\
		= \frac{e^{-(n_{S}+n_{B})}(n_{S}+n_{B})^{N}}{N!} \prod_{i=1}^{N} [f_{S}P_{S}(M_{lb}^i) + f_{B}P_{B}(M_{lb}^i)] \\
		 = \frac{e^{-(n_{S}+n_{B})}}{N!} \prod_{i=1}^{N} [n_{S}P_{S}(M_{lb}^i) + n_{B}P_{B}(M_{lb}^i)]
		\end{split}
		\label{eq:ext_likelihood_fn_this}
		\end{equation}

		Eventually, in our analysis we use binned-likelihood function as the observed mode. In other words, the $i=1,2,\ldots,N$ means that input observations are the the i-th bin results of N bins under the observable -- $M_{lb}$ spectrum. By contrast, the unbinned-likelihood method uses event-by-event as the observation(i means the i-th event), costing too much resource and time, so it has not been used.


		\subsubsection{Fitting Result}
		\label{sssec:FittingResult}

		With the Maximum-Likelihood Method, there is the fitting result(Fig.\ref{BkgEst:fig:fit_result_yields}). The signal template is $t\bar{t}$ MC in SR and the background template is real data in CR, both are under $M_{lb}$ spectrum.

		\begin{figure}[H]
		\centering
			\subfigure[$\chi^2_{min}$, mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/[mu]new_chi2_fit.pdf}}
			\subfigure[$\chi^2_{min}$, el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/[el]new_chi2_fit.pdf}}\\
		\end{figure}
		\FloatBarrier
		\begin{figure}[H]
		\centering
			\subfigure[MVA(20 variables, MLP), mu-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/[mu]new_a05_MLP_fit.pdf}}
			\subfigure[MVA(20 variables, MLP), el-ch]{\includegraphics[width=0.45\textwidth]{Figures/BackgroundEstimation/[el]new_a05_MLP_fit.pdf}}\\
		\caption{Results of template fit, with fitted yields ccomparing data and MC.($\chi^2$, MVA methods are both shown)}
		\label{BkgEst:fig:fit_result_yields}
		\end{figure}
		\FloatBarrier

		Futhermore, the fitted yields of signal($t\bar{t}$) and background are shown under $\chi^2$ and MVA cases(Table.\ref{BkgEst:tb:DataMC_est_chi2}, \ref{BkgEst:tb:DataMC_est_MVAA}, \ref{BkgEst:tb:DataMC_est_MVAB}).

		\begin{center}
		\begin{longtable}[H]{ c c c }
		\caption{Data and MC estimated events number after template fit(w/ $\chi^2_{min}, M_{lb}$ cut)} \\
		\hline
		 & Muon Channel & Electron Channel \\ 
		\hline
		 Data & 243790 & 136151 \\
		\hline
		 Estimated $t\bar{t}$ & 230766 & 135600 \\
		 Estimated background & 12146.9 & 5537.45 \\
		\hline
		\label{BkgEst:tb:DataMC_est_chi2}
		\end{longtable}
		\end{center}
		\FloatBarrier

		\begin{center}
		\begin{longtable}[H]{ c c c }
		\caption{Data and MC estimated events number after template fit(w/ MVA-A strategy)} \\
		\hline
		 & Muon Channel & Electron Channel \\ 
		\hline
		 Data & 245436 & 139432 \\
		\hline
		 Estimated $t\bar{t}$ & 236226 & 133894  \\
		 Estimated background & 8520.95 & 5102.1 \\
		\hline
		\label{BkgEst:tb:DataMC_est_MVAA}
		\end{longtable}
		\end{center}
		\FloatBarrier

		\begin{center}
		\begin{longtable}[H]{ c c c }
		\caption{Data and MC estimated events number after template fit(w/ MVA-B strategy)} \\
		\hline
		 & Muon Channel & Electron Channel \\ 
		\hline
		 Data & 272583 & 157510 \\
		\hline
		 Estimated $t\bar{t}$ & 256196 & 146656 \\
		 Estimated background & 15479 & 10217.6 \\
		\hline
		\label{BkgEst:tb:DataMC_est_MVAB}
		\end{longtable}
		\end{center}
		\FloatBarrier

		\subsubsection{Goodness of Fit}
		\label{sssec:GoF}

		It is necessary to check whether it is fine to use the fitting result. There is a common method to test the goodness of fit -- $\boldsymbol{\chi^2}$ $\textbf{test}$. In a set of 2 data histogram, we use the $\chi^2$ value between them to see the degree they match to each other. In general case, $\chi^2$ value are the sum of N independent normal variables distribution, shown below(Eq.\ref{eq:chi2_dis}). The $\chi^2(N)$ and $P(x)$ in Eq.\ref{eq:chi2_dis} is also a distribution called $\chi^2$ distribution. The only parameter of $\chi^2$ distribution is the N which also means $\emph{degree of freedom}$. Degree of freedom means the number of independent terms in one distribution which affect the variation of this distribution. 
		The basic concept to apply $\chi^2$ to test goodness of fit is -- to see all the N independent variables in histogram as normal distribution and operate them to be standard, and then sum all of them to compare with the corresponding $\chi^2(N)$ distribution. Commonly, we see where the derived $\chi^2$ value drop on the corresponding $\chi^2$ distribution and take the p-value as the criteria. If p-value is large, and this means one data distribution is not so match to the other one, and vice versa. For simlified one criteria, if 2 set of data points are well match to each, the derived $\chi^2$ value should be close to expectation value of corresponding $\chi^2(N)$ distribution -- N.

		\begin{equation}
		\begin{split}
		Q = \sum_{i=1}^{N} X_i^2 \implies \chi^2(N) \\ %\; \; \; , \; X_i = Gaus(x)_{standard}\\
		\chi^2(N) \implies P(x) = \frac{\frac{1}{2}(\frac{x}{2})^{\frac{N}{2} - 1}e^{-\frac{x}{2}}}{\Gamma (\frac{N}{2})} \\
		Exp<P(x)> = N \; \; (D.o.F)
		\label{eq:chi2_dis}
		\end{split}
		\end{equation}

		For this analysis, to compare the 2 histogram under 1 variable's spectrum, it is usually taken the events number in any bins as independent variables. There are 1 set of real data points and 1 set of MC points which follows the fitting result. And then, to standardize all the bins' variables to be normal distribution variables, we operate them as Eq.\ref{eq:chi2_dis_this}'s first equation. After standardization, we just sum up all the bins' operated variables to be the $\chi^2$ value of these 2 sets of data points (Eq.\ref{eq:chi2_dis_this}-2). The $x^d_i$ means the events number of real data in i-th bin, $x^s_i$ is the events number of MC in i-th bin. Also, the standard error for standardization is poisson error of counting events number of MC in i-th bin -- $\sqrt{x^s_i}$:

		\begin{equation}
		\begin{split}
		X_i = \frac{x^d_i - x^s_i}{\sqrt{x^s_i}} \\
		Q = \sum_{i=1}^{N} X_i^2 = \sum_{i=1}^{N} \frac{(x^d_i - x^s_i)^2}{(\sqrt{x^s_i})^2}
		\label{eq:chi2_dis_this}
		\end{split}
		\end{equation}

		In this case, the bins range under $M_{lb}$ is from 0GeV to 500GeV with 50 bins. The parameters $n_S$, $n_B$ in fitting give these data points 2 constraint, so the degree of freedom of these data points are (50-2)=48. So with the simple method, there are the comparison between derived $\chi^2$ value($Q$) to the expectation value 48 $\longrightarrow$ $\frac{Q}{48}$, there are the goodness of fit under $\chi^2_{min}$ and MVA reconstruction strategy.

		\begin{center}
		\begin{longtable}[H]{ c c c }
		\caption{$\frac{Q}{D.o.F}$ of fitting results ($\chi^2_{min}$ and MVA strategy)} \\
		\hline
		 & Muon Channel & Electron Channel \\ 
		\hline
		$\chi^2_{min}$ & 2.54258 & 1.39517 \\
		MVA & 2.52261 & 2.15768 \\
		\hline
		\label{BkgEst:tb:goodness_of_fit}
		\end{longtable}
		\end{center}
		\FloatBarrier

		We can see that in electron channel we have better fitting demonstration than in muon channel. However, it is fine to have these goodness-of-fit results under all cases.

	\subsection{Background subtraction}
	\label{ssec:bkg_sub}

		The final target of background subtraction is using the fitted yields results to subtract the background contribution in $A'_{cp}$. The process are shown below as a illustration diagram(Fig.\ref{BkgEst:fig:Bkt_sub}). First of all, we use signal and background templates to do the template fit and get fitted yields $N_{data}$ and $N_{bkg}$ which both include positive and negative value of specific observable. Secondly, subtract both the positive and negative observable's yields of background from data's part, and there are the effective positive and negative observable's yields $N(O>0)_{eff}.$ and $N(O<0)_{eff}.$. Therefore, the final $A'_{cp}$ can be calculated by effective yields which are expected purely contributed by signal($t\bar{t}$).

		\begin{figure}[H]
		\centering{}
	    	\includegraphics[width=0.85\textwidth]{Figures/BackgroundEstimation/bkg_sub_1.pdf}\\
		\end{figure}
		\FloatBarrier
		\begin{figure}[H]
		\centering{}
	    	\includegraphics[width=0.85\textwidth]{Figures/BackgroundEstimation/bkg_sub_2.pdf}\\
		\caption{Process of background subtraction}
		\label{BkgEst:fig:Bkt_sub}
		\end{figure}
		\FloatBarrier


\FloatBarrier
